{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer IT Support Text Classification with DistilBERT (3 Classes)\n",
    "\n",
    "This notebook performs text classification using DistilBERT with 3 consolidated classes:\n",
    "1. Technical/IT Support (Technical Support, IT Support)\n",
    "2. Customer & Product Support (Customer Service, Product Support)\n",
    "3. Financial/Other (Billing and Payments, Returns and Exchanges, Service Outages and Maintenance, Sales and Pre-Sales, Human Resources, General Inquiry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path to import local modules\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Initialize TensorFlow correctly to avoid import conflicts\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Use GPU if available and set memory growth to avoid OOM errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to true for all GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs available: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error configuring GPUs: {e}\")\n",
    "\n",
    "# Regular imports after TensorFlow is initialized\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Import the DistilBERT implementation after TensorFlow is properly initialized\n",
    "from src.model import DistilBertClassifier, save_model, load_model, model_predict\n",
    "from src.utils import encode_texts, encode_labels, load_training_conf\n",
    "from src.train import define_callbacks, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Class Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "train_path = \"../data/ticket_train.csv\"\n",
    "valid_path = \"../data/ticket_valid.csv\"\n",
    "test_path = \"../data/ticket_test.csv\"\n",
    "\n",
    "# Define columns\n",
    "text_column = \"text_en\"  \n",
    "label_column = \"queue\"  \n",
    "\n",
    "# Load configuration for defaults\n",
    "conf = load_training_conf()\n",
    "max_length = 192  # Increase max sequence length for better context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, text_column, label_column, tokenizer=None, unique_labels=None):\n",
    "    \"\"\"Load and process a dataset file with consolidated categories\"\"\"\n",
    "    # Try different delimiters\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=\";\")\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=\",\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not read file {file_path} with delimiter ',' or ';': {e}\")\n",
    "    \n",
    "    print(f\"Loaded {file_path} with {len(df)} rows\")\n",
    "    \n",
    "    # Get text and labels\n",
    "    texts = df[text_column].tolist()\n",
    "    labels = df[label_column].tolist()\n",
    "    \n",
    "    # Initialize tokenizer if not provided\n",
    "    if tokenizer is None:\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "        tokenizer.max_length = max_length\n",
    "        tokenizer.pad_to_max_length = True\n",
    "\n",
    "    # Get unique labels if not provided\\n\",\n",
    "    if unique_labels is None:\n",
    "      unique_labels = sorted(list(set(labels)))\n",
    "    \n",
    "    # Encode labels\n",
    "    encoded_labels = encode_labels(labels, unique_labels)\n",
    "    \n",
    "    # Encode texts\n",
    "    print(f\"\\nTokenizing texts from {file_path}...\")\n",
    "    encoded_texts = encode_texts(tokenizer, texts)\n",
    "    \n",
    "    return encoded_texts, encoded_labels, tokenizer, unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets \n",
    "x_train, y_train, tokenizer, unique_labels = load_dataset(train_path, text_column, label_column)\n",
    "x_valid, y_valid, _, _ = load_dataset(valid_path, text_column, label_column, tokenizer)\n",
    "x_test, y_test, _, _ = load_dataset(test_path, text_column, label_column, tokenizer)\n",
    "\n",
    "# Print dataset info\n",
    "print(f\"Number of classes: {len(unique_labels)}\"),\n",
    "print(f\"Unique labels: {unique_labels}\"),\n",
    "print(f\"\\nTraining samples: {len(y_train)}\")\n",
    "print(f\"Validation samples: {len(y_valid)}\")\n",
    "print(f\"Test samples: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory before model creation\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Create the DistilBERT model with optimized hyperparameters\n",
    "model = DistilBertClassifier(\n",
    "    num_labels=3,  # 3 consolidated categories\n",
    "    learning_rate=3e-5,  # Slightly lower learning rate for better generalization\n",
    "    dropout_rate=0.2,  \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "print(\"Model created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimized callbacks\n",
    "callbacks = define_callbacks(\n",
    "    patience=3,  \n",
    "    min_delta=0.003,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate scheduler for better convergence\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.8  # Decay learning rate by 20% after epoch 2\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "callbacks.append(lr_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with optimized settings\n",
    "BATCH_SIZE = 16  # Larger batch size for better optimization since we have fewer classes\n",
    "EVAL_BATCH_SIZE = 32\n",
    "\n",
    "train_loss, train_accuracy = train_model(\n",
    "    model,\n",
    "    x_train,  \n",
    "    x_valid,  \n",
    "    y_train,\n",
    "    y_valid,\n",
    "    epochs=8,  # More epochs for better convergence with 3 classes\n",
    "    batch_size=BATCH_SIZE,  \n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"Validation Loss: {train_loss:.4f}, Validation Accuracy: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "# Clear memory before prediction\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Use batched prediction\n",
    "y_pred_logits = model.predict_in_batches(x_test, batch_size=16)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=consolidated_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix with improved visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot normalized confusion matrix with improved aesthetics\n",
    "ax = sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=consolidated_categories, yticklabels=consolidated_categories, \n",
    "            annot_kws={\"size\": 14}, linewidths=0.5, cbar=False)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('True', fontsize=14)\n",
    "plt.title('Normalized Confusion Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add percentages in each cell\n",
    "for i in range(len(consolidated_categories)):\n",
    "    for j in range(len(consolidated_categories)):\n",
    "        text = ax.texts[i * len(consolidated_categories) + j]\n",
    "        text.set_text(f\"{cm_norm[i, j]:.2f}\\n({cm[i, j]})\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Analysis to Improve Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original test data to analyze misclassifications\n",
    "try:\n",
    "    test_df = pd.read_csv(test_path, delimiter=\";\")\n",
    "except:\n",
    "    test_df = pd.read_csv(test_path, delimiter=\",\")\n",
    "\n",
    "# Add consolidated categories and predictions\n",
    "test_df['consolidated_queue'] = test_df[label_column].apply(map_to_consolidated_category)\n",
    "test_df['predicted_queue'] = [consolidated_categories[i] for i in y_pred]\n",
    "test_df['correctly_classified'] = test_df['consolidated_queue'] == test_df['predicted_queue']\n",
    "\n",
    "# Find misclassified examples\n",
    "misclassified = test_df[~test_df['correctly_classified']]\n",
    "\n",
    "# Analyze examples from each error type\n",
    "print(\"Most common misclassification patterns:\")\n",
    "error_patterns = misclassified.groupby(['consolidated_queue', 'predicted_queue']).size().reset_index()\n",
    "error_patterns.columns = ['True Category', 'Predicted Category', 'Count']\n",
    "error_patterns = error_patterns.sort_values('Count', ascending=False)\n",
    "display(error_patterns.head(5))\n",
    "\n",
    "# Show some examples of the most common misclassification\n",
    "most_common_error = error_patterns.iloc[0]\n",
    "true_cat = most_common_error['True Category']\n",
    "pred_cat = most_common_error['Predicted Category']\n",
    "\n",
    "print(f\"\\nExamples of {true_cat} tickets misclassified as {pred_cat}:\")\n",
    "examples = misclassified[\n",
    "    (misclassified['consolidated_queue'] == true_cat) & \n",
    "    (misclassified['predicted_queue'] == pred_cat)\n",
    "].head(5)\n",
    "\n",
    "for i, (_, row) in enumerate(examples.iterrows()):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Text: {row[text_column][:200]}...\")\n",
    "    print(f\"Original Queue: {row[label_column]}\")\n",
    "    print(f\"True Category: {row['consolidated_queue']}\")\n",
    "    print(f\"Predicted: {row['predicted_queue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model_folder = \"../models/distilbert_3class\"\n",
    "save_model(model, tokenizer, model_folder=model_folder)\n",
    "\n",
    "# Save consolidated categories for prediction\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "with open(f\"{model_folder}/categories.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(consolidated_categories))\n",
    "    \n",
    "print(f\"Model, tokenizer, and category labels saved to {model_folder}/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Predictions on New Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on new examples\n",
    "# Clear memory before running predictions\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "test_examples = [\n",
    "    \"I need help with my email account, I can't login to the system\",\n",
    "    \"My server is down and customers can't access our website. This is urgent!\",\n",
    "    \"I would like to request a refund for the software purchase I made last week\",\n",
    "    \"Can you help me understand how to use the new reporting feature?\",\n",
    "    \"We need to update our subscription to include more licenses for the team\",\n",
    "    \"The network connection in the east wing office is very slow\",\n",
    "    \"I have a question about my recent invoice. There seems to be an extra charge.\"\n",
    "]\n",
    "\n",
    "# Get predictions using small batch size\n",
    "pred_indices = model_predict(model, tokenizer, test_examples, batch_size=2)\n",
    "predictions = [consolidated_categories[idx] for idx in pred_indices]\n",
    "\n",
    "# Display results with confidence scores\n",
    "encoded_examples = encode_texts(tokenizer, test_examples)\n",
    "pred_logits = model.predict_in_batches(encoded_examples, batch_size=2)\n",
    "pred_probs = tf.nn.softmax(pred_logits, axis=1).numpy()\n",
    "\n",
    "print(\"Prediction Results:\\n\")\n",
    "for i, (example, prediction, probs) in enumerate(zip(test_examples, predictions, pred_probs)):\n",
    "    confidence = probs.max() * 100\n",
    "    print(f\"Example {i+1}:\\nText: {example}\\n\")\n",
    "    print(f\"Predicted category: {prediction} (Confidence: {confidence:.2f}%)\\n\")\n",
    "    \n",
    "    # Show probabilities for all categories\n",
    "    print(\"Probabilities for each category:\")\n",
    "    for j, category in enumerate(consolidated_categories):\n",
    "        print(f\"  {category}: {probs[j]*100:.2f}%\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
